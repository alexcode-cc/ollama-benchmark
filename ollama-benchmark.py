import html
import json
import time
from datetime import datetime
from pathlib import Path

import requests

OLLAMA_BASE_URL = "http://localhost:11434"
CHATS_DIR = Path(__file__).resolve().parent / "chats"

BENCHMARK_PROMPTS = [
    {
        "name": "greeting",
        "prompt": "ä½ å¥½ï¼Œè«‹ä»¥ç¹é«”ä¸­æ–‡ç°¡å–®è‡ªæˆ‘ä»‹ç´¹ã€‚",
    },
    {
        "name": "reasoning",
        "prompt": "å¦‚æœä¸€å€‹æˆ¿é–“è£¡æœ‰ 3 å€‹äººï¼Œæ¯å€‹äººå„é¤Š 2 éš»è²“ï¼Œè«‹å•æˆ¿é–“è£¡ç¸½å…±æœ‰å¹¾éš»è…³ï¼Ÿè«‹èªªæ˜ç†ç”±ã€‚",
    },
    {
        "name": "coding",
        "prompt": "è«‹ç”¨ Python å¯«ä¸€å€‹å‡½å¼ï¼Œåˆ¤æ–·ä¸€å€‹æ•¸å­—æ˜¯å¦ç‚ºè³ªæ•¸ã€‚",
    },
    {
        "name": "expression",
        "prompt": "è«‹ç”¨ç¹é«”ä¸­æ–‡è§£é‡‹ä»€éº¼æ˜¯ RESTful APIï¼Œå°è±¡æ˜¯å‡è¨­å®Œå…¨æ²’æœ‰æŠ€è¡“èƒŒæ™¯çš„äººã€‚",
    },
]

# Chart.js èª¿è‰²ç›¤
CHART_COLORS = [
    "rgba(54, 162, 235, 0.8)",
    "rgba(255, 99, 132, 0.8)",
    "rgba(75, 192, 192, 0.8)",
    "rgba(255, 206, 86, 0.8)",
    "rgba(153, 102, 255, 0.8)",
    "rgba(255, 159, 64, 0.8)",
    "rgba(46, 204, 113, 0.8)",
    "rgba(231, 76, 60, 0.8)",
]

CHART_BORDERS = [c.replace("0.8", "1") for c in CHART_COLORS]

# ---------------------------------------------------------------------------
# Ollama API
# ---------------------------------------------------------------------------

def get_available_models() -> list[str]:
    resp = requests.get(f"{OLLAMA_BASE_URL}/api/tags", timeout=30)
    resp.raise_for_status()
    data = resp.json()
    return [m["name"] for m in data.get("models", [])]


def ollama_generate(model: str, prompt: str) -> dict:
    start = time.time()
    resp = requests.post(
        f"{OLLAMA_BASE_URL}/api/generate",
        json={"model": model, "prompt": prompt, "stream": False},
        timeout=600,
    )
    latency = round(time.time() - start, 3)
    resp.raise_for_status()
    text = resp.json().get("response", "")
    return {"response": text, "latency": latency, "length": len(text)}


# ---------------------------------------------------------------------------
# è©•æ¸¬åŸ·è¡Œ
# ---------------------------------------------------------------------------

def run_benchmark_for_model(model: str) -> list[dict]:
    print("=" * 70)
    print(f"ğŸ Benchmark é–‹å§‹ï¼š{model}")
    print("=" * 70)

    results: list[dict] = []
    for item in BENCHMARK_PROMPTS:
        print(f"â–¶ æ¸¬è©¦é …ç›®ï¼š{item['name']}")
        try:
            result = ollama_generate(model, item["prompt"])
            print(f"  â± {result['latency']}s | ğŸ“ {result['length']} chars")
            results.append({
                "test": item["name"],
                "prompt": item["prompt"],
                **result,
                "success": True,
            })
        except Exception as e:
            print(f"  âŒ å¤±æ•—ï¼š{e}")
            results.append({
                "test": item["name"],
                "prompt": item["prompt"],
                "response": "",
                "latency": None,
                "length": 0,
                "success": False,
                "error": str(e),
            })
    return results


def interactive_chat(model: str) -> None:
    print("\nğŸ’¬ é€²å…¥äººå·¥äº’å‹•æ¨¡å¼ï¼ˆEnter / n çµæŸï¼‰")
    while True:
        user_input = input("ä½ ï¼š").strip()
        if user_input.lower() in ("n", "no", ""):
            break
        reply = ollama_generate(model, user_input)
        print(f"{model}ï¼š\n{reply['response']}\n")


# ---------------------------------------------------------------------------
# HTML å ±å‘Šç”Ÿæˆ
# ---------------------------------------------------------------------------

def _build_html_report(report: dict) -> str:
    """æ ¹æ“šè©•æ¸¬å ±å‘Š dict ç”¢ç”Ÿè‡ªåŒ…å«çš„ HTML åˆ†æé é¢ï¼ˆå« Chart.js äº’å‹•åœ–è¡¨ï¼‰"""

    models = list(report["models"].keys())
    test_names = [p["name"] for p in BENCHMARK_PROMPTS]
    timestamp = report["generated_at"]

    # ---- è³‡æ–™æº–å‚™ ----
    # latency_data[test_name] = [model1_latency, model2_latency, ...]
    latency_data: dict[str, list[float | None]] = {t: [] for t in test_names}
    length_data: dict[str, list[int]] = {t: [] for t in test_names}

    for model in models:
        benchmarks = report["models"][model]["benchmark"]
        test_map = {b["test"]: b for b in benchmarks}
        for t in test_names:
            b = test_map.get(t, {})
            latency_data[t].append(b.get("latency"))
            length_data[t].append(b.get("length", 0))

    # å„æ¨¡å‹å¹³å‡å»¶é² & ç¸½å›æ‡‰é•·åº¦
    avg_latencies: list[float] = []
    total_lengths: list[int] = []
    for i, model in enumerate(models):
        lats = [latency_data[t][i] for t in test_names if latency_data[t][i] is not None]
        avg_latencies.append(round(sum(lats) / len(lats), 3) if lats else 0)
        total_lengths.append(sum(length_data[t][i] for t in test_names))

    # ç°¡çŸ­æ¨¡å‹åç¨±ï¼ˆç”¨æ–¼åœ–è¡¨æ¨™ç±¤ï¼‰
    short_names = [m.split(":")[0] if ":" in m else m for m in models]

    # é¡è‰²
    colors = [CHART_COLORS[i % len(CHART_COLORS)] for i in range(len(models))]
    borders = [CHART_BORDERS[i % len(CHART_BORDERS)] for i in range(len(models))]

    # ---- æ¨¡å‹è©³ç´°å›è¦† HTML ----
    details_html = ""
    for model in models:
        benchmarks = report["models"][model]["benchmark"]
        details_html += f'<div class="model-detail"><h3>{html.escape(model)}</h3>'
        for b in benchmarks:
            status = "âœ…" if b.get("success") else "âŒ"
            lat = f'{b["latency"]}s' if b.get("latency") is not None else "N/A"
            details_html += f"""
            <div class="test-card">
              <div class="test-header">
                <span class="test-name">{status} {html.escape(b['test'])}</span>
                <span class="test-stats">â± {lat} | ğŸ“ {b.get('length', 0)} chars</span>
              </div>
              <div class="prompt">ğŸ’¬ {html.escape(b['prompt'])}</div>
              <details><summary>å±•é–‹å›è¦†</summary>
                <pre class="response">{html.escape(b.get('response', '') or '(ç„¡å›è¦†)')}</pre>
              </details>
            </div>"""
        details_html += "</div>"

    # ---- æ‘˜è¦è¡¨æ ¼ ----
    summary_rows = ""
    for i, model in enumerate(models):
        benchmarks = report["models"][model]["benchmark"]
        success_count = sum(1 for b in benchmarks if b.get("success"))
        summary_rows += f"""
        <tr>
          <td>{html.escape(model)}</td>
          <td>{avg_latencies[i]}s</td>
          <td>{total_lengths[i]}</td>
          <td>{success_count}/{len(test_names)}</td>
        </tr>"""

    return f"""<!DOCTYPE html>
<html lang="zh-Hant">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Ollama Benchmark åˆ†æå ±å‘Š - {timestamp}</title>
<script src="https://cdn.jsdelivr.net/npm/chart.js@4"></script>
<style>
  :root {{
    --bg: #0f1117; --surface: #1a1d27; --border: #2a2d3a;
    --text: #e4e6eb; --muted: #8b8fa3; --accent: #3b82f6;
  }}
  * {{ margin: 0; padding: 0; box-sizing: border-box; }}
  body {{
    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', system-ui, sans-serif;
    background: var(--bg); color: var(--text); padding: 2rem; line-height: 1.6;
  }}
  h1 {{ text-align: center; margin-bottom: .3rem; font-size: 1.8rem; }}
  .subtitle {{ text-align: center; color: var(--muted); margin-bottom: 2rem; }}
  .grid {{ display: grid; grid-template-columns: 1fr 1fr; gap: 1.5rem; margin-bottom: 2rem; }}
  @media (max-width: 900px) {{ .grid {{ grid-template-columns: 1fr; }} }}
  .card {{
    background: var(--surface); border: 1px solid var(--border);
    border-radius: 12px; padding: 1.5rem;
  }}
  .card h2 {{ font-size: 1.1rem; margin-bottom: 1rem; color: var(--accent); }}
  .card-full {{ grid-column: 1 / -1; }}
  table {{ width: 100%; border-collapse: collapse; }}
  th, td {{ padding: .6rem .8rem; text-align: left; border-bottom: 1px solid var(--border); }}
  th {{ color: var(--muted); font-weight: 600; font-size: .85rem; text-transform: uppercase; }}
  td {{ font-size: .95rem; }}
  canvas {{ width: 100% !important; max-height: 350px; }}
  .model-detail {{ margin-bottom: 2rem; }}
  .model-detail h3 {{
    font-size: 1.15rem; padding: .8rem 0; border-bottom: 2px solid var(--accent);
    margin-bottom: 1rem;
  }}
  .test-card {{
    background: var(--surface); border: 1px solid var(--border);
    border-radius: 8px; padding: 1rem; margin-bottom: .8rem;
  }}
  .test-header {{ display: flex; justify-content: space-between; align-items: center; margin-bottom: .5rem; }}
  .test-name {{ font-weight: 600; }}
  .test-stats {{ color: var(--muted); font-size: .85rem; }}
  .prompt {{ color: var(--muted); font-size: .9rem; margin-bottom: .5rem; }}
  details summary {{
    cursor: pointer; color: var(--accent); font-size: .9rem;
    padding: .3rem 0; user-select: none;
  }}
  .response {{
    white-space: pre-wrap; word-break: break-word; font-size: .85rem;
    background: var(--bg); padding: 1rem; border-radius: 8px;
    margin-top: .5rem; max-height: 400px; overflow-y: auto; line-height: 1.5;
  }}
</style>
</head>
<body>

<h1>Ollama Benchmark åˆ†æå ±å‘Š</h1>
<p class="subtitle">æ¸¬è©¦æ™‚é–“ï¼š{timestamp}</p>

<!-- æ‘˜è¦è¡¨æ ¼ -->
<div class="grid">
  <div class="card card-full">
    <h2>ğŸ“‹ æ¨¡å‹ç¸½è¦½</h2>
    <table>
      <thead><tr><th>æ¨¡å‹</th><th>å¹³å‡å»¶é²</th><th>ç¸½å›æ‡‰é•·åº¦</th><th>æˆåŠŸç‡</th></tr></thead>
      <tbody>{summary_rows}</tbody>
    </table>
  </div>

  <!-- å¹³å‡å»¶é²æ¯”è¼ƒ -->
  <div class="card">
    <h2>â± å¹³å‡å›æ‡‰å»¶é²ï¼ˆç§’ï¼‰</h2>
    <canvas id="chartAvgLatency"></canvas>
  </div>

  <!-- ç¸½å›æ‡‰é•·åº¦æ¯”è¼ƒ -->
  <div class="card">
    <h2>ğŸ“ ç¸½å›æ‡‰é•·åº¦ï¼ˆå­—å…ƒï¼‰</h2>
    <canvas id="chartTotalLength"></canvas>
  </div>

  <!-- å„æ¸¬è©¦é …ç›®å»¶é² -->
  <div class="card">
    <h2>â± å„æ¸¬è©¦é …ç›®å»¶é²æ¯”è¼ƒï¼ˆç§’ï¼‰</h2>
    <canvas id="chartLatencyByTest"></canvas>
  </div>

  <!-- å„æ¸¬è©¦é …ç›®å›æ‡‰é•·åº¦ -->
  <div class="card">
    <h2>ğŸ“ å„æ¸¬è©¦é …ç›®å›æ‡‰é•·åº¦æ¯”è¼ƒï¼ˆå­—å…ƒï¼‰</h2>
    <canvas id="chartLengthByTest"></canvas>
  </div>
</div>

<!-- æ¨¡å‹è©³ç´°å›è¦† -->
<div class="card card-full" style="margin-bottom:2rem;">
  <h2>ğŸ’¬ å„æ¨¡å‹è©³ç´°å›è¦†</h2>
  {details_html}
</div>

<script>
const MODELS = {json.dumps(short_names, ensure_ascii=False)};
const MODELS_FULL = {json.dumps(models, ensure_ascii=False)};
const TESTS = {json.dumps(test_names, ensure_ascii=False)};
const COLORS = {json.dumps(colors)};
const BORDERS = {json.dumps(borders)};
const AVG_LATENCIES = {json.dumps(avg_latencies)};
const TOTAL_LENGTHS = {json.dumps(total_lengths)};
const LATENCY_DATA = {json.dumps(latency_data, ensure_ascii=False)};
const LENGTH_DATA = {json.dumps(length_data, ensure_ascii=False)};

Chart.defaults.color = '#8b8fa3';
Chart.defaults.borderColor = '#2a2d3a';

// å¹³å‡å»¶é²
new Chart(document.getElementById('chartAvgLatency'), {{
  type: 'bar',
  data: {{
    labels: MODELS,
    datasets: [{{
      label: 'å¹³å‡å»¶é²ï¼ˆç§’ï¼‰',
      data: AVG_LATENCIES,
      backgroundColor: COLORS,
      borderColor: BORDERS,
      borderWidth: 1
    }}]
  }},
  options: {{
    responsive: true,
    plugins: {{ legend: {{ display: false }} }},
    scales: {{ y: {{ beginAtZero: true, title: {{ display: true, text: 'ç§’' }} }} }}
  }}
}});

// ç¸½å›æ‡‰é•·åº¦
new Chart(document.getElementById('chartTotalLength'), {{
  type: 'bar',
  data: {{
    labels: MODELS,
    datasets: [{{
      label: 'ç¸½å›æ‡‰é•·åº¦ï¼ˆå­—å…ƒï¼‰',
      data: TOTAL_LENGTHS,
      backgroundColor: COLORS,
      borderColor: BORDERS,
      borderWidth: 1
    }}]
  }},
  options: {{
    responsive: true,
    plugins: {{ legend: {{ display: false }} }},
    scales: {{ y: {{ beginAtZero: true, title: {{ display: true, text: 'å­—å…ƒ' }} }} }}
  }}
}});

// å„æ¸¬è©¦å»¶é²ï¼ˆåˆ†çµ„é•·æ¢åœ–ï¼‰
new Chart(document.getElementById('chartLatencyByTest'), {{
  type: 'bar',
  data: {{
    labels: TESTS,
    datasets: MODELS.map((m, i) => ({{
      label: m,
      data: TESTS.map(t => LATENCY_DATA[t][i] ?? 0),
      backgroundColor: COLORS[i],
      borderColor: BORDERS[i],
      borderWidth: 1
    }}))
  }},
  options: {{
    responsive: true,
    plugins: {{ legend: {{ position: 'bottom' }} }},
    scales: {{ y: {{ beginAtZero: true, title: {{ display: true, text: 'ç§’' }} }} }}
  }}
}});

// å„æ¸¬è©¦å›æ‡‰é•·åº¦
new Chart(document.getElementById('chartLengthByTest'), {{
  type: 'bar',
  data: {{
    labels: TESTS,
    datasets: MODELS.map((m, i) => ({{
      label: m,
      data: TESTS.map(t => LENGTH_DATA[t][i]),
      backgroundColor: COLORS[i],
      borderColor: BORDERS[i],
      borderWidth: 1
    }}))
  }},
  options: {{
    responsive: true,
    plugins: {{ legend: {{ position: 'bottom' }} }},
    scales: {{ y: {{ beginAtZero: true, title: {{ display: true, text: 'å­—å…ƒ' }} }} }}
  }}
}});
</script>

</body>
</html>"""


# ---------------------------------------------------------------------------
# ä¸»æµç¨‹
# ---------------------------------------------------------------------------

def main():
    models = get_available_models()
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    report: dict = {
        "generated_at": timestamp,
        "models": {},
    }

    print("ğŸ“¦ åµæ¸¬åˆ°æ¨¡å‹ï¼š")
    for m in models:
        print(f" - {m}")
    print()

    for model in models:
        benchmark_results = run_benchmark_for_model(model)
        report["models"][model] = {"benchmark": benchmark_results}

        choice = input("\næ˜¯å¦è¦èˆ‡æ­¤æ¨¡å‹äº’å‹•ï¼Ÿ(y/N)ï¼š ").strip().lower()
        if choice == "y":
            interactive_chat(model)

    # å»ºç«‹æ™‚é–“æˆ³è¨˜ç›®éŒ„
    run_dir = CHATS_DIR / f"benchmark_{timestamp}"
    run_dir.mkdir(parents=True, exist_ok=True)

    # è¼¸å‡º JSON å ±å‘Š
    json_file = run_dir / "benchmark_report.json"
    with open(json_file, "w", encoding="utf-8") as f:
        json.dump(report, f, ensure_ascii=False, indent=2)

    # è¼¸å‡º HTML åˆ†æå ±å‘Šï¼ˆå«åœ–è¡¨ï¼‰
    html_file = run_dir / "benchmark_report.html"
    with open(html_file, "w", encoding="utf-8") as f:
        f.write(_build_html_report(report))

    print(f"\nâœ… Benchmark å®Œæˆï¼å ±å‘Šå·²è¼¸å‡ºè‡³ï¼š{run_dir}")
    print(f"   ğŸ“„ JSON å ±å‘Šï¼š{json_file.name}")
    print(f"   ğŸ“Š åˆ†æåœ–è¡¨ï¼š{html_file.name}")


if __name__ == "__main__":
    main()
