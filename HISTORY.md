# 版本歷史

## 1.0.0（2026-02-06）

首次正式發佈。

### 基準測試工具（ollama-benchmark.py）

- 自動偵測 Ollama 伺服器上所有可用模型
- 4 項標準化測試：greeting（問候）、reasoning（推理）、coding（程式碼生成）、expression（表達能力）
- 測量回應延遲（秒）與回應長度（字元）
- 產生 JSON 原始數據報告
- 產生互動式 HTML 分析報告，包含 Chart.js 圖表：
  - 模型總覽表格（平均延遲、總回應長度、成功率）
  - 平均回應延遲比較圖
  - 總回應長度比較圖
  - 各測試項目延遲比較（分組長條圖）
  - 各測試項目回應長度比較（分組長條圖）
  - 各模型詳細回覆（可展開）
- 每次測試在 `chats/` 下建立獨立時間戳記目錄
- `--auto` 自動模式參數，跳過互動確認
- 可選的互動式聊天模式

### 互動式聊天工具（hi-ai.py）

- 依序對每個可用模型進行打招呼測試
- Streaming 模式接收模型回應
- 30 秒打招呼逾時控制，超時自動跳過
- 每次切換模型前自動卸載所有已載入模型（透過 `/api/chat` + `keep_alive: 0`）
- OOM（記憶體不足）診斷機制：
  - 透過 `/api/ps` 查詢模型載入狀態
  - 區分載入階段逾時 vs 生成階段逾時
  - 偵測 OOM 相關錯誤訊息關鍵字
  - 顯示其他佔用記憶體的模型資訊
- 收到第一個 token 後即時顯示模型資源佔用（VRAM / 系統記憶體）
- 互動選項：y=繼續交談、n=下一個模型、q=離開程式
- 所有輸出使用 `flush=True` 確保即時顯示

### 專案基礎建設

- Python >= 3.10，核心依賴僅 `requests >= 2.28.0`
- 使用 hatchling 建置系統，支援 uv / pip 安裝
- MIT 授權
- 完整技術文件（`docs/` 目錄）：
  - 系統架構總覽
  - hi-ai.py 技術文件
  - ollama-benchmark.py 技術文件
  - Ollama API 串接說明
  - 錯誤處理與 OOM 診斷機制
- Git Commit Message 規範文件（CLAUDE.md）
